{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ad4967-fc0d-449b-8ace-ec6351f73d33",
   "metadata": {},
   "source": [
    "# Model Evaluation Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c4cc3-8ca7-4066-8e4d-415db47db53d",
   "metadata": {},
   "source": [
    "## Regression Models Evaluation\n",
    "\n",
    "To demonstrate evaluation, we won't be using any regression model but will generate original values and predictions from the model by Numpy instead. Let's begin by importing Numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069f09d7-4683-4b0c-a822-88f57822680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f051e30-b755-415a-b602-fadedbeb7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.random.normal(0,1,10)\n",
    "\n",
    "errors = np.random.normal(0,0.02,10)\n",
    "\n",
    "y_pred = y_true + errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cbd59-5277-4f26-80b6-2f1008da1e83",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE) / Root Means Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bac3ec-6c0f-4287-b24b-6f6f26a9c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003650544411545718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae93e662-8ae2-4995-846e-87e54e341023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019106397911552345\n",
      "0.019106397911552345\n"
     ]
    }
   ],
   "source": [
    "RMSE = np.sqrt(MSE)\n",
    "print(RMSE)\n",
    "\n",
    "RMSE = mean_squared_error(y_true, y_pred, squared=False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da6b29-1e77-4549-979e-de7c7e7e72ce",
   "metadata": {},
   "source": [
    "### Classification Models Evaluation\n",
    "\n",
    "We will use the same principle as in regression model evaluation and use synthetic data. With the only difference that we will need predicted probabilities instead of predicted labels (predicted values in regression). The important thing to mention is that we are simulating the behavior of a binary classifier. It means that the predicted class is only positive (returns 1) or negative (returns 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e281fc8d-8ee8-453f-af6c-f5ce50ed5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1,1,0,1,0,0,1,0,0,1]\n",
    "\n",
    "y_proba = [0.9,0.7,0.2,0.99,0.7,0.1,0.5,0.2,0.4,0.6]\n",
    "\n",
    "thres = 0.5\n",
    "\n",
    "y_pred = [int(value > thres) for value in y_proba]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20321e5e-33b6-4b19-b430-e60bb2a54d59",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b07cf4-ce7b-4527-84d9-a2f564801915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0052d0-1744-44ec-9379-4a3ce9dbbe96",
   "metadata": {},
   "source": [
    "#### F1 - Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9b1b2a1-226f-4579-9c92-80ef6f067058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1f8c4-31d7-4488-8cd7-2c090385a71f",
   "metadata": {},
   "source": [
    "#### AUC-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76bbfbd9-186f-4b7d-a1bf-e28ab81634e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e1fad-fd57-45a6-8ecd-18d8db0be497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
