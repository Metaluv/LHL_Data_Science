{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Online Learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will do the first online learning in Python. We will use demo data that we split manually into the batches and we \"assume\" they are coming in a real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data for this tutorial [**here**](https://drive.google.com/file/d/1WeylXMG4JZ_wxyqjz6MgjwpMI4ZVkdFz/view?usp=sharing). It's a NBA dataset we have used in exercises for probability and statistics. It consists of statistics and result of each NBA game in 3 regular seasons 2013-2015.\n",
    "\n",
    "We will use statistics from regular season games to predict if teams won or lost in playoffs. You can find a playoff dataset [**here**](https://drive.google.com/file/d/15cx7LsopbCZ9WQ5CbGZHK_Dp-IPDrRqF/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and keep only the columns we will need in this tutorial\n",
    "data_path = \"/Users/jurajkapasny/Data/NBA/\"\n",
    "df = pd.read_csv(data_path + \"nba_games_2013_2015.csv\",sep=\";\")\n",
    "# we want to keep only these statistics\n",
    "cols_to_keep = ['GAME_DATE','WL', 'PTS', 'FGM', 'FGA', 'FG_PCT',\n",
    "       'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB',\n",
    "       'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF']\n",
    "df = df[cols_to_keep]\n",
    "# convert to datetime\n",
    "df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
    "df = df.sort_values('GAME_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For initial training , we will use only games from 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_train = df[df.GAME_DATE.dt.year == 2013]\n",
    "first_train = first_train.drop(\"GAME_DATE\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now , we need to prepare our target variable, `WL`. We will convert it into 0 and 1 using LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "first_train.WL = le.fit_transform(first_train.WL.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how our dataset looks like now:\n",
    "first_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract y and X from the dataset\n",
    "y_first = first_train.WL\n",
    "X_first = first_train.drop(\"WL\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and keep only the columns we will need in this tutorial\n",
    "data_path = \"/Users/jurajkapasny/Data/NBA/\"\n",
    "play_offs = pd.read_csv(data_path + \"nba_playoff_games_2016.csv\",sep=\";\")\n",
    "# we want to keep only these statistics\n",
    "cols_to_keep = ['WL', 'PTS', 'FGM', 'FGA', 'FG_PCT',\n",
    "       'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB',\n",
    "       'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF']\n",
    "play_offs = play_offs[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_offs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Warning\n",
    "> It's important to use ONLY .transform() for LabelEncoder here. We don't want to accidentaly end up with different numbers for W and L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_offs.WL = le.transform(play_offs.WL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract y and X from the dataset\n",
    "y_test = play_offs.WL\n",
    "X_test = play_offs.drop(\"WL\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the **Stochastic Gradient Descent Classifier (SGDClassifier)**. The only difference with most other methods is that they actually optimize their coefficients using only one observation at a time (Using Stochastic Gradient Descent). It therefore takes more iterations before it reaches comparable results to a classic ridge or lasso regression, but it requires much less memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Note\n",
    "> SGD is sensitive to the scale of variables, and that’s not just because of regularization, it’s because of the way it works internally. Consequently, we should always standardize our features (for instance, by using StandardScaler) or you force them in the range [0,+1] or [-1,+1]. We will have poorer results if we don't do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# metrics for evaluation\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = StandardScaler()\n",
    "scaling.fit(X_first)\n",
    "X_first = scaling.transform(X_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = SGDClassifier(loss='log')\n",
    "# we will use .partial_fit() method. This will allow us to train on new data incrementaly. \n",
    "# When using online learning, we need to specify the final list of classes. \n",
    "# It might happen that we miss some classes in the first batch of data.\n",
    "SGD.partial_fit(X_first, y_first, classes=np.unique(y_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_test, SGD.predict(X_test)))\n",
    "print(\"\")\n",
    "print(\"Precision\")\n",
    "print(precision_score(y_test, SGD.predict(X_test)))\n",
    "print(\"\")\n",
    "print(\"Recall\")\n",
    "print(recall_score(y_test, SGD.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our model is not good. The good precision is caused by very small number of cases where we actually predicted `WIN`. We can also have different results because if depends on the initial weights in Stochastic Gradient Descent.\n",
    "\n",
    "Now, let's see if we can improve the model when we have new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Learning\n",
    "We will be adding a new data day by day and look for some improvements in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract the rest of the data\n",
    "other_data = df[df.GAME_DATE.dt.year != 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will put all unique dates into the list\n",
    "all_dates = list(other_data.GAME_DATE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test if this works\n",
    "df[df.GAME_DATE == all_dates[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = list()\n",
    "precision = list()\n",
    "recall = list()\n",
    "for day in all_dates:\n",
    "    train = df[df.GAME_DATE == day]\n",
    "    train = train.drop(\"GAME_DATE\", axis = 1)\n",
    "    # Extract y and X from the dataset\n",
    "    train.WL = le.transform(train.WL)\n",
    "    y_train = train.WL\n",
    "    X_train = train.drop(\"WL\", axis = 1)\n",
    "    \n",
    "\n",
    "    X_train = scaling.transform(X_train)\n",
    "    \n",
    "    # partial fit on new data\n",
    "    SGD.partial_fit(X_train, y_train)\n",
    "    # storing improvements (if any :))\n",
    "    acc.append(accuracy_score(y_test, SGD.predict(X_test)))\n",
    "    precision.append(precision_score(y_test, SGD.predict(X_test), zero_division=False))\n",
    "    recall.append(recall_score(y_test, SGD.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of performance over the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1,21),np.abs(acc[:20]),'o--')\n",
    "plt.xlabel('Partial fit initial iterations')\n",
    "plt.ylabel('Test set mean squared error')\n",
    "plt.title(\"Accuracy First 20 Iterations\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(0,len(acc),50),np.abs(acc[0:len(acc):50]),'o--')\n",
    "plt.xlabel('Partial fit ending iterations')\n",
    "plt.title(\"Accuracy Overall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1,21),np.abs(precision[:20]),'o--')\n",
    "plt.xlabel('Partial fit initial iterations')\n",
    "plt.ylabel('Test set mean squared error')\n",
    "plt.title(\"Precission First 20 Iterations\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(0,len(precision),50),np.abs(precision[0:len(precision):50]),'o--')\n",
    "plt.xlabel('Partial fit ending iterations')\n",
    "plt.title(\"Precission Overall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1,21),np.abs(recall[:20]),'o--')\n",
    "plt.xlabel('Partial fit initial iterations')\n",
    "plt.ylabel('Test set mean squared error')\n",
    "plt.title(\"Recall First 20 Iterations\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(0,len(recall),50),np.abs(recall[0:len(recall):50]),'o--')\n",
    "plt.xlabel('Partial fit ending iterations')\n",
    "plt.title(\"Recall Overall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that that we were able to improve our original performance. But the best model is somewhere in the middle of all iterations.\n",
    "\n",
    "> #### Warning\n",
    "> We need to be careful because new data doesn't always mean better model. We should always test a new version and replace the old one only if there is an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
