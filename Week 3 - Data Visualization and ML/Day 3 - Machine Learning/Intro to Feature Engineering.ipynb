{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Dec 10, 2021\n",
    "\n",
    "Jason Cardinal Exercise Notebook Lighthouse Labs - Intro to Feature Engineering\n",
    "\n",
    "[https://data.compass.lighthouselabs.ca/days/w03d3/activities/465]\n",
    "\n",
    "this notebook contains the code along notes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are more likely to come up with a great feature set rather than invent a new ML algorithm. Therefore, it's very important to spend some quality time on the phase of Machine Learning called Feature Engineering."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering is equally an art as it is a science. It tries to find a good representation of behavior observed with data. But what is good?\n",
    "\n",
    "We need to start with our intuition and verify it by testing over time.\n",
    "\n",
    "In some cases, data preparation can be considered as the first step in feature engineering so in some resources, you will find it together.\n",
    "\n",
    "https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discover Feature Engineering, How to Engineer Features and How to Get Good at It\n",
    "\n",
    "Feature engineering is an informal topic, but one that is absolutely known and agreed to be key to success in applied machine learning.\n",
    "\n",
    "### Problem that Feature Engineering Solves\n",
    "\n",
    "When your goal is to get the best possible results from a predictive model, you need to get the most from what you have.\n",
    "\n",
    "### Importance of Feature Engineering\n",
    "\n",
    "The features in your data will directly influence the predictive models you use and the results you can achieve. Better features that you prepare and choose, the better the result. The results you achieve are a factor of the model you choose; data available, prepared features, framing of the problem, objective measures for estimate of accuracy. Your results are dependent on many interdependent properties. You need great feature that describe the structures inherent in your data.\n",
    "\n",
    "#### Better features means flexibility\n",
    "\n",
    "The flexibility of good deatures will allow you to use less complex models that are faster to run easier to understand and easier to maintain.\n",
    "\n",
    "#### Better features means simpler models\n",
    "\n",
    "With good features, you are closer to the underlying problem and a representation of all the data you have available and could use to best characterize that problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is Future Engineering?\n",
    "\n",
    "Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see the dependencies in this definition:\n",
    "\n",
    "* The performance measures you’ve chosen (RMSE? AUC?)\n",
    "* The framing of the problem (classification? regression?)\n",
    "* The predictive models you’re using (SVM?)\n",
    "* The raw data you have selected and prepared (samples? formatting? cleaning?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A picture relevant to our discussion on feature engineering is the front-middle of this process. It might look something like the following:\n",
    "\n",
    "1. (tasks before here…)\n",
    "2. **Select Data**: Integrate data, de-normalize it into a dataset, collect it together.\n",
    "3. **Preprocess Data**: Format it, clean it, sample it so you can work with it.\n",
    "4. **Transform Data**: Feature Engineer happens here.\n",
    "5. **Model Data**: Create models, evaluate them and tune them.\n",
    "6. (tasks after here…)\n",
    "\n",
    "The traditional idea of “Transforming Data” from a raw state to a state suitable for modeling is where feature engineering fits in. Transform data and feature engineering may in fact be synonyms."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iterative Process of Feature Engineering\n",
    "\n",
    "Knowing where feature engineering fits into the context of the process of applied machine learning highlights that it does not standalone.\n",
    "\n",
    "It is an iterative process that interplays with data selection and model evaluation, again and again, until we run out of time on our problem.\n",
    "\n",
    "The process might look as follows:\n",
    "\n",
    "1. **Brainstorm features**: Really get into the problem, look at a lot of data, study feature engineering on other problems and see what you can steal.\n",
    "2. **Devise features**: Depends on your problem, but you may use automatic feature extraction, manual feature construction and mixtures of the two.\n",
    "3. **Select features**: Use different feature importance scorings and feature selection methods to prepare one or more “views” for your models to operate upon.\n",
    "4. **Evaluate models**: Estimate model accuracy on unseen data using the chosen features.\n",
    "\n",
    "You need a well defined problem so that you know when to stop this process and move on to trying other models, other model configurations, ensembles of models, and so on. There are gains to be had later in the pipeline once you plateau on ideas or the accuracy delta.\n",
    "\n",
    "You need a well considered and designed test harness for objectively estimating model skill on unseen data. It will be the only measure you have of your feature engineering process, and you must trust it not to waste your time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://miro.medium.com/max/700/1*2T5rbjOBGVFdSvtlhCqlNg.png"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "“Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.”\n",
    "— Dr. Jason Brownlee"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering on Numeric Data\n",
    "\n",
    "Numeric data typically represents data in the form of scalar values depicting observations, recordings or measurements. Here, by numeric data, we mean continuous data and not discrete data which is typically represented as categorical data. Numeric data can also be represented as a vector of values where each value or entity in the vector can represent a specific feature. Integers and floats are the most common and widely used numeric data types for continuous numeric data. Even though numeric data can be directly fed into machine learning models, you would still need to engineer features which are relevant to the scenario, problem and domain before building a model. Hence the need for feature engineering still remains."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sometimes, supervised and unsupervised algorithms are useful in feature engineering. We will learn the concepts in this reading but we won't practice it yet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using ML in Feature Engineering\n",
    "\n",
    "#### Supervised Learning\n",
    "\n",
    "We are using the output of a prediction to predict something else. It can be powerful but potentially dangerous because we introduce some errors into the data.\n",
    "\n",
    "* **Prediction of a missing value**: We use features without missing values in our dataset to train the predictor of missing values. The variable with missing values is our target variable.\n",
    "* **Outlier detection**: This can be supervised learning if we have marked the outliers in previous observations, for example, fraudulent credit card transactions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Unsupervised Learning\n",
    "\n",
    "We are assigning new categories to all observations based on unsupervised learning. Some basic concepts are:\n",
    "\n",
    "* **Outlier detection**: The outliers are assigned to a separate cluster.\n",
    "* **Feature creation**: Cluster is a new variable that can be used for prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}