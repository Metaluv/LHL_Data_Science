{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Dec 10, 2021\n",
    "\n",
    "Jason Cardinal Exercise Notebook Lighthouse Labs - Types of Learning\n",
    "\n",
    "[https://data.compass.lighthouselabs.ca/days/w03d4/activities/473]\n",
    "\n",
    "this notebook contains the code along notes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to continue growing our foundations of Machine Learning. We will now learn some basics like what \"learning\" actually means and which different types of ML are there."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading\n",
    "\n",
    "#### What is \"Learning\"?\n",
    "\n",
    "We can define \"learning\" as the process of turning **experience** into **expertise**, where: - Experience: training data, measurements, observations - Expertise: the ability to perform some task\n",
    "\n",
    "There are also some examples from animal learning (brains of living creatures work very similarly):\n",
    "\n",
    "* **Bait Shyness**: Rats learn to avoid poisonous bites by first trying small chunks.\n",
    "* **Pigeon Superstition**: Ringing a bell a minute before feeding, i.e. overfitting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Types of Learning\n",
    "\n",
    "Machine Learning can be divided into several subfields but the most important two are : - Supervised learning - Unsupervised learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Supervised Learning\n",
    "\n",
    "In this type of ML, we can say that learning is guided by a teacher (a target variable). We use a dataset that acts as a teacher and its role is to train the model (e.g. our House Prediction Data from the previous days). Once the model is trained it can make a prediction or decision when new data are fed to it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Unsupervised Learning\n",
    "\n",
    "This type of learning model learns by observing data and finds structures in it. It automatically finds patterns and relationships in the dataset by creating clusters (groups) in it.\n",
    "\n",
    "There are also some other types.\n",
    "\n",
    "https://machinelearningmastery.com/types-of-learning-in-machine-learning/\n",
    "\n",
    "Our focus for the rest of this module is going to be the unsupervised learning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is Clustering?\n",
    "\n",
    "Clustering is the task of dividing a population or data points into several groups in a way that data points in the same groups are more similar to each other than to those in other groups. Simply said, the aim is to segregate groups with similar traits and assign them into clusters.\n",
    "\n",
    "https://www.geeksforgeeks.org/clustering-in-machine-learning/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section will explain how centroid-based clustering works. As a representative of this group of models, we have chosen the famous k-means algorithm."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-means\n",
    "\n",
    "In centroid-based clustering, clusters are represented by a central vector, which may not necessarily be a member of the dataset. When the number of clusters is fixed to k, k-means clustering gives a formal definition as an optimization problem: find the k cluster centers and assign the objects to the nearest cluster center such that the squared distances from the cluster are minimized.\n",
    "\n",
    "https://youtu.be/4b5d3muPQmA\n",
    "\n",
    "https://towardsdatascience.com/k-means-clustering-from-a-to-z-f6242a314e9a\n",
    "\n",
    "#### The Algorithm\n",
    "\n",
    "K-means clustering is a good place to start exploring an unlabeled dataset. The K in K-Means denotes the number of clusters. This algorithm is bound to converge to a solution after some iterations. It has 4 basic steps:\n",
    "\n",
    "1. Initialize Cluster Centroids (Choose those 3 books to start with)\n",
    "2. Assign datapoints to Clusters (Place remaining the books one by one)\n",
    "3. Update Cluster centroids (Start over with 3 different books)\n",
    "4. Repeat step 2–3 until the stopping condition is met.\n",
    "\n",
    "You don’t have to start with 3 clusters initially, but 2–3 is generally a good place to start, and update later on.\n",
    "\n",
    "https://miro.medium.com/max/640/1*xkuet4YVglp8KWsK90bfRw.gif"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Initialize K & Centroids\n",
    "\n",
    "As a starting point, you tell your model how many clusters it should make. First the model picks up K, (let K = 3) datapoints from the dataset. These datapoints are called cluster centroids.\n",
    "Now there are different ways you to initialize the centroids, you can either choose them at random — or sort the dataset, split it into K portions and pick one datapoint from each portion as a centriod."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Assigning Clusters to datapoints\n",
    "\n",
    "From here on wards, the model performs calculations on it’s own and assigns a cluster to each datapoint. Your model would calculate the distance between the datapoint & all the centroids, and will be assigned to the cluster with the nearest centroid. Again, there are different ways you can calculate this distance; all having their pros and cons. Usually we use the L2 distance.\n",
    "\n",
    "https://miro.medium.com/max/616/1*q2DjVeZIlLmLcKXDQJ9yEA.png"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Updating Centroids\n",
    "\n",
    "Because the initial centroids were chosen arbitrarily, your model the updates them with new cluster values. The new value might or might not occur in the dataset, in fact, it would be a coincidence if it does. This is because the updated cluster centorid is the average or the mean value of all the datapoints within that cluster.\n",
    "\n",
    "https://miro.medium.com/max/615/1*25LCusv4wAWPxfa7zJoOYA.png\n",
    "\n",
    "Now if some other algo, like K-Mode, or K-Median was used, instead of taking the average value, mode and median would be taken respectively.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Stopping Criterion\n",
    "\n",
    "Since step 2 and 3 would be performed iteratively, it would go on forever if we don’t set a stopping criterion. The stopping criterion tells our algo when to stop updating the clusters. It is important to note that setting a stopping criterion would not necessarily return THE BEST clusters, but to make sure it returns reasonably good clusters, and more importantly at least return some clusters, we need to have a stopping criterion.\n",
    "\n",
    "Like everything else, there are different ways to set the stopping criterion. You can even set multiple conditions that, if met, would stop the iteration and return the results. Some of the stopping conditions are:\n",
    "\n",
    "1. The datapoints assigned to specific cluster remain the same (takes too much time)\n",
    "2. Centroids remain the same (time consuming)\n",
    "3. The distance of datapoints from their centroid is minimum (the thresh you’ve set)\n",
    "4. Fixed number of iterations have reached (insufficient iterations → poor results, choose max iteration wisely)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating the cluster quality\n",
    "\n",
    "The goal here isn’t just to make clusters, but to make good, meaningful clusters. Quality clustering is when the datapoints within a cluster are close together, and afar from other clusters.\n",
    "\n",
    "The two methods to measure the cluster quality are described below:\n",
    "\n",
    "1. **Inertia**: Intuitively, inertia tells how far away the points within a cluster are. Therefore, a small of inertia is aimed for. The range of inertia’s value starts from zero and goes up.\n",
    "2. **Silhouette score**: Silhouette score tells how far away the datapoints in one cluster are, from the datapoints in another cluster. The range of silhouette score is from -1 to 1. Score should be closer to 1 than -1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How many clusters?\n",
    "\n",
    "You have to specify the number of clusters you want to make. There are a few methods available to choose the optimal number of K. The direct method is to just plot the datapoints and see if it gives you a hint. As you can see in the figure below, making 3 clusters seems like a good choice.\n",
    "\n",
    "https://miro.medium.com/max/850/1*dCn1eA4pf-SPzAWz-pIN5A.png\n",
    "\n",
    "Other method is to use the value of inertia. The idea behind good clustering is having a small value of inertia, and small number of clusters.\n",
    "The value of inertia decreases as the number of clusters increase. So, its a trade-off here. Rule of thumb: The elbow point in the inertia graph is a good choice because after that the change in the value of inertia isn’t significant.\n",
    "\n",
    "https://miro.medium.com/max/440/1*xOGY4uu6ng7E8lPLP-onWw.png\n",
    "\n",
    "#### Naming your Clusters\n",
    "\n",
    "When you’ve formed a cluster, you give a name it, and all the datapoints in that cluster are assigned this name as their label. Now your dataset has labels! You can perform testing using these labels. To find insights about your data, you can see what similarity do the datapoints within a cluster have, and how does it differ from other clusters.\n",
    "\n",
    "#### Assigning a cluster to a new data point\n",
    "\n",
    "Once you’ve finalized your model, it can now assign a cluster to a new data point. The method of assigning cluster remains same, i.e., assigning it to the cluster with the closet centroid.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Warning!\n",
    "\n",
    "It’s important to preprocess your data before performing K-Means. You would have to convert your dataset into numerical values if it is not already, so that calculations can be performed. Also, applying feature reduction techniques would speed up the process, and also improve the results. These steps are important to follow because K-Means is sensitive to outliers, just like every other algo that uses average/mean values. Following these steps alleviate these issues."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}