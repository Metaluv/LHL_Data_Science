{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting stable-baselines3[extra]\n  Downloading stable_baselines3-1.0-py3-none-any.whl (152 kB)\nRequirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.6.0)\nRequirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.2.4)\nRequirement already satisfied: numpy in c:\\users\\jesse\\appdata\\roaming\\python\\python38\\site-packages (from stable-baselines3[extra]) (1.19.5)\nRequirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.3.4)\nRequirement already satisfied: torch>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.9.0)\nCollecting gym>=0.17\n  Downloading gym-0.18.3.tar.gz (1.6 MB)\nCollecting opencv-python\n  Downloading opencv_python-4.5.2.54-cp38-cp38-win_amd64.whl (34.7 MB)\nRequirement already satisfied: tensorboard>=2.2.0 in c:\\users\\jesse\\appdata\\roaming\\python\\python38\\site-packages (from stable-baselines3[extra]) (2.5.0)\nRequirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.8.0)\nRequirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (8.2.0)\nCollecting atari-py~=0.2.0\n  Downloading atari_py-0.2.9-cp38-cp38-win_amd64.whl (1.6 MB)\nRequirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from atari-py~=0.2.0->stable-baselines3[extra]) (1.15.0)\nRequirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from gym>=0.17->stable-baselines3[extra]) (1.6.2)\nCollecting pyglet<=1.5.15,>=1.4.0\n  Downloading pyglet-1.5.15-py3-none-any.whl (1.1 MB)\nRequirement already satisfied: protobuf>=3.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.17.2)\nRequirement already satisfied: markdown>=2.6.8 in c:\\users\\jesse\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.4)\nRequirement already satisfied: google-auth<2,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.30.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jesse\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.4)\nRequirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.36.2)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\nRequirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.0)\nRequirement already satisfied: grpcio>=1.24.3 in c:\\users\\jesse\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.34.1)\nRequirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (52.0.0.post20210125)\nRequirement already satisfied: absl-py>=0.4 in c:\\users\\jesse\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.12.0)\nRequirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.25.1)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.7.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (1.26.4)\nRequirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2020.12.5)\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.1.1)\nRequirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.4.0->stable-baselines3[extra]) (3.7.4.3)\nRequirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.1)\nRequirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2021.1)\nBuilding wheels for collected packages: gym\n  Building wheel for gym (setup.py): started\n  Building wheel for gym (setup.py): finished with status 'done'\n  Created wheel for gym: filename=gym-0.18.3-py3-none-any.whl size=1657517 sha256=6712e73ce621a6275dcf43d109109858cec2cdcc0bf4d25506343d78a587193f\n  Stored in directory: c:\\users\\jesse\\appdata\\local\\pip\\cache\\wheels\\b3\\03\\54\\9141c232861b89be935b37bdde0ea5ab472f5e18fc20623aed\nSuccessfully built gym\nInstalling collected packages: pyglet, gym, stable-baselines3, opencv-python, atari-py\nSuccessfully installed atari-py-0.2.9 gym-0.18.3 opencv-python-4.5.2.54 pyglet-1.5.15 stable-baselines3-1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "import os \n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment \n",
    "\n",
    "environment_name = 'CartPole-v0'\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episod: 1 Score: 24.0\n",
      "Episod: 2 Score: 12.0\n",
      "Episod: 3 Score: 18.0\n",
      "Episod: 4 Score: 21.0\n",
      "Episod: 5 Score: 42.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "  state = env.reset()\n",
    "  done = False\n",
    "  score = 0 \n",
    "  while not done:\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    n_state, reward, done, info = env.step(action)\n",
    "    score += reward\n",
    "  print('Episod: {} Score: {}'.format(episode, score))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# understanding the environment\n",
    "\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-4.5120394e-01,  7.3608409e+37,  3.4732372e-01, -6.2629789e+37],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "source": [
    "# trainning \n",
    "types of algorithms \n",
    "model vs model free: learning based on predictsion of next state/reward or real samples. \n",
    "\n",
    "stable baselines focuses on model free algorithms\n",
    "\n",
    "Choosing algorithms \n",
    "there are a number of algorithms available through stable baseliness as shown to the right. we can easily switch between each of these. \n",
    "certain algorithms will perform better for certain environements. Often it helps to review literature in order to determine the best approach. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "understanding trainning metrics \n",
    "evaluation metrics: \n",
    "ep_len_mean, eo_rew_mean\n",
    "\n",
    "time metrics:\n",
    "fps, iterations, time_elapsed, total_timestpes\n",
    "\n",
    "loss metrics:\n",
    "entropy_loss, policy_loss, value_loss\n",
    "\n",
    "other metrics:\n",
    "explained_variance, learning_rate, n_updates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make your directories first\n",
    "log_path = os.path.join('Trainning', 'Logs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Trainning\\\\Logs'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logging to Trainning\\Logs\\PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2793 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035090137 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000822    |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1433         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032536513 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 41.8         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 92.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042404844 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1334         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022409647 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.554       |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 66.1         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008573649 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.537      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.6        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006896601 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000747   |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1279         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046821134 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.4         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1274         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037096783 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007522808 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.7        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x18116726070>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and reload mdoel \n",
    "PPO_Path = os.path.join('Trainning', \"Saved Models\", 'PPO_Model_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_Path, env = env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logging to Trainning\\Logs\\PPO_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2750 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1811db5adf0>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "source": [
    "# evaluation \n",
    "There are a number of metrics available from the modesl when trained but two core values that you should pay attention to:\n",
    "ep_len_mean: on average how long a particular episode lasted before done\n",
    "ep_rew_mean: the average rewardd that the agent accumulated per episode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Monitoring in tensorboard \n",
    "you are able to review evaluation, time and trainning modetrics from within tensorboard\n",
    "in order to do so you must specify a logging directory when you initialise your model \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _ = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episod: 1 Score: [200.]\n",
      "Episod: 2 Score: [200.]\n",
      "Episod: 3 Score: [200.]\n",
      "Episod: 4 Score: [200.]\n",
      "Episod: 5 Score: [200.]\n"
     ]
    }
   ],
   "source": [
    "# test model \n",
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  score = 0 \n",
    "  while not done:\n",
    "    env.render()\n",
    "    action, _  = model.predict(obs) # now we are using model here \n",
    "    obs, reward, done, info = env.step(action)\n",
    "    score += reward\n",
    "  print('Episod: {} Score: {}'.format(episode, score))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _ = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[-0.03568621,  0.18240808, -0.00432363, -0.3119863 ]],\n",
       "       dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([False]),\n",
       " [{}])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing logs in tensorboard \n",
    "trainning_log_path = os.path.join(log_path, 'PPO_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Trainning\\\\Logs\\\\PPO_2'"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "trainning_log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# this doesn't work for some reason, just run it in command prompt and use the follow code \n",
    "!python -m tensorboard.main --logdir=trainning_log_path\n",
    "\n",
    "#!tensorboard --logdir={trainning_log_path}"
   ]
  },
  {
   "source": [
    "# core metrics to look at \n",
    "* Average reward\n",
    "* average episode length \n",
    "\n",
    "trainning strategies \n",
    "* train for longer \n",
    "* hyperparameter tuning \n",
    "* try different algorithms \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# applying callbacks \n",
    "you can leverage callback functions as part of stable baselines to log out data or save the model under certain conditions \n",
    "# using different algorithms \n",
    "stable baselines comes pre-packaged with a number of different algorithms that can be used to train you agent "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Trainning', 'Saved Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200, verbose = 1)\n",
    "eval_callback = EvalCallback(env,\n",
    "                            callback_on_new_best=stop_callback,\n",
    "                            eval_freq=10000,\n",
    "                            best_model_save_path=save_path,\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logging to Trainning\\Logs\\PPO_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 3095 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1847        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008498399 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.000221   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1670        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010121268 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.0838      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009224874 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "Eval num_timesteps=10000, episode_reward=200.00 +/- 0.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 200.00  is above the threshold 200\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1811e355670>"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change policies\n",
    "net_arch = [dict(pi=[128,128,128,128], vf=[128,128,128,128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path, policy_kwargs={'net_arch': net_arch})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logging to Trainning\\Logs\\PPO_5\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2602 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1811db8b850>"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "model.learn(total_timesteps=2000,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using alternate algorithm\n",
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = DQN('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  | 652      |\n",
      "|    fps              | 13305    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 14501    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 13311    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 14614    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 13322    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 14706    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 13314    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 14777    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 13324    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 14895    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 13331    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 14969    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 13334    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15053    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 13337    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15163    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 13334    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15226    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 13335    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15307    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 13336    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15415    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 13341    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15514    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 13359    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15656    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 13347    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15722    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 13363    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15847    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 13359    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15909    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 13346    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 15974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 13355    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16065    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 13356    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16120    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 13345    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16186    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 13362    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 13353    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16343    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 13348    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16404    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 13352    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16488    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 13347    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16549    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 13354    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16651    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 13363    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16756    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 13367    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16841    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 13362    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 16926    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 13375    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17025    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 13382    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17141    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 13371    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17208    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 13375    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17293    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 13389    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17445    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 13388    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17511    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 13385    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 13395    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17680    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 13394    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17746    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 13373    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17838    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 13371    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17929    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 13369    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 17993    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 13373    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18106    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 13370    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18182    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 13378    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18273    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 13387    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18352    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 13386    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18418    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 13380    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18504    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 13385    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18564    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 13384    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18630    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 13396    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18726    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 13392    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18842    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 13403    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18937    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 13393    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 18977    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 13385    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19033    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 13387    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19142    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 13391    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19229    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 13388    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19304    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 13395    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19408    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 13404    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19515    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 13405    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19610    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 13414    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19731    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 13399    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19790    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 13406    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19866    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 13401    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 19939    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x1811da79700>"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}