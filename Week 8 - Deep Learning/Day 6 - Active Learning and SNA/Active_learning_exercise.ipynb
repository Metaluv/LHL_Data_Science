{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the titanic dataset here: https://drive.google.com/file/d/0Bz9_0VdXvv9bbVhpOEMwUDJ2elU/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will simulate active learning. We will keep the small sample of observations for testing and we will test how quality of the model rises when we use active learning to choose labeled observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data into variable df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SAMPLE\n",
    "# USE THIS SAMPLE ONLY FOR TESTING\n",
    "test_df = df.sample(n=100, random_state=42)\n",
    "# KEEP ONLY THOSE WHO ARE NOT IN THE TEST SET\n",
    "df = df[~df.PassengerId.isin(test_df.PassengerId.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT THE FIRST MODEL ONLY ON THE DATAFRAME START_DF\n",
    "start_df = df.sample(n=100, random_state=42)\n",
    "# DROP OBS FROM START_DF FROM DF\n",
    "df = df[~df.PassengerId.isin(start_df.PassengerId.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. fit the first model only on the **start_df** using **SVM** and evaluate accuracy, precision and recall on test_df\n",
    "2. in each iteration, add 10 observations from **df** to your trainset (choose the observation using active learning approach) \n",
    "    - score all observations in df and take 10 where the model isn't sure what class it is. The probability of surviving will be around 50% \n",
    "3. refit the model and evaluate on **test_df** again.    \n",
    "3. the goal is to converge to the optimal solution as fast as possible by choosing **right** observations in each iteration\n",
    "4. plot the graphs for each eval metric, where on the axis x is iteration number, on y is the metric value for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = start_df.Survived\n",
    "X = start_df.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# # Keep selected columns only\n",
    "# my_cols = categorical_cols + numerical_cols\n",
    "# X_train = X_train_full[my_cols].copy()\n",
    "# X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Sex',\n",
       " 'Cabin',\n",
       " 'Embarked',\n",
       " 'PassengerId',\n",
       " 'Pclass',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare']"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "my_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1_score: 0.8181818181818182\n              precision    recall  f1-score   support\n\n           0       0.78      0.78      0.78         9\n           1       0.82      0.82      0.82        11\n\n    accuracy                           0.80        20\n   macro avg       0.80      0.80      0.80        20\nweighted avg       0.80      0.80      0.80        20\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, f1_score, accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = f1_score(y_valid, preds)\n",
    "print('f1_score:', score)\n",
    "print(classification_report(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.1586335 , 0.04325159, 0.10075011, 0.05318166, 0.05493281,\n",
       "       0.17610446, 0.11483511, 0.16138958, 0.04605794, 0.00056524,\n",
       "       0.00483148, 0.00211161, 0.00361104, 0.00104185, 0.00400778,\n",
       "       0.00245905, 0.00239306, 0.02641228, 0.01216763, 0.03126221])"
      ]
     },
     "metadata": {},
     "execution_count": 175
    }
   ],
   "source": [
    "my_pipeline.named_steps['model'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(80, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['Sex',\n",
    " 'Cabin',\n",
    " 'Embarked',\n",
    " 'PassengerId',\n",
    " 'Pclass',\n",
    " 'Age',\n",
    " 'SibSp',\n",
    " 'Parch',\n",
    " 'Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preds = my_pipeline.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = df_test_preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argsort()\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = find_nearest(df_preds, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([339, 252, 465, 331, 446, 337, 346, 423, 144, 328], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "sorted_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "df_preds[446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "452          453         0       1   \n",
       "331          332         0       1   \n",
       "607          608         1       1   \n",
       "440          441         1       2   \n",
       "580          581         1       2   \n",
       "450          451         0       2   \n",
       "460          461         1       1   \n",
       "555          556         0       1   \n",
       "183          184         1       2   \n",
       "432          433         1       2   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "452                    Foreman, Mr. Benjamin Laventall    male  30.0      0   \n",
       "331                                Partner, Mr. Austen    male  45.5      0   \n",
       "607                        Daniel, Mr. Robert Williams    male  27.0      0   \n",
       "440        Hart, Mrs. Benjamin (Esther Ada Bloomfield)  female  45.0      1   \n",
       "580                        Christy, Miss. Julie Rachel  female  25.0      1   \n",
       "450                              West, Mr. Edwy Arthur    male  36.0      1   \n",
       "460                                Anderson, Mr. Harry    male  48.0      0   \n",
       "555                                 Wright, Mr. George    male  62.0      0   \n",
       "183                          Becker, Master. Richard F    male   1.0      2   \n",
       "432  Louch, Mrs. Charles Alexander (Alice Adelaide ...  female  42.0      1   \n",
       "\n",
       "     Parch        Ticket   Fare Cabin Embarked  \n",
       "452      0        113051  27.75  C111        C  \n",
       "331      0        113043  28.50  C124        S  \n",
       "607      0        113804  30.50   NaN        S  \n",
       "440      1  F.C.C. 13529  26.25   NaN        S  \n",
       "580      1        237789  30.00   NaN        S  \n",
       "450      2    C.A. 34651  27.75   NaN        S  \n",
       "460      0         19952  26.55   E12        S  \n",
       "555      0        113807  26.55   NaN        S  \n",
       "183      1        230136  39.00    F4        S  \n",
       "432      0    SC/AH 3085  26.00   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>452</th>\n      <td>453</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Foreman, Mr. Benjamin Laventall</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113051</td>\n      <td>27.75</td>\n      <td>C111</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>332</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Partner, Mr. Austen</td>\n      <td>male</td>\n      <td>45.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113043</td>\n      <td>28.50</td>\n      <td>C124</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>608</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Daniel, Mr. Robert Williams</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113804</td>\n      <td>30.50</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>440</th>\n      <td>441</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Hart, Mrs. Benjamin (Esther Ada Bloomfield)</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>F.C.C. 13529</td>\n      <td>26.25</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>580</th>\n      <td>581</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Christy, Miss. Julie Rachel</td>\n      <td>female</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>237789</td>\n      <td>30.00</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>450</th>\n      <td>451</td>\n      <td>0</td>\n      <td>2</td>\n      <td>West, Mr. Edwy Arthur</td>\n      <td>male</td>\n      <td>36.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C.A. 34651</td>\n      <td>27.75</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>460</th>\n      <td>461</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Anderson, Mr. Harry</td>\n      <td>male</td>\n      <td>48.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19952</td>\n      <td>26.55</td>\n      <td>E12</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>556</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Wright, Mr. George</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113807</td>\n      <td>26.55</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>184</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Becker, Master. Richard F</td>\n      <td>male</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>230136</td>\n      <td>39.00</td>\n      <td>F4</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>433</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Louch, Mrs. Charles Alexander (Alice Adelaide ...</td>\n      <td>female</td>\n      <td>42.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>SC/AH 3085</td>\n      <td>26.00</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "df.iloc[list(sorted_index[:10]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PassengerId                                453\n",
       "Survived                                     0\n",
       "Pclass                                       1\n",
       "Name           Foreman, Mr. Benjamin Laventall\n",
       "Sex                                       male\n",
       "Age                                       30.0\n",
       "SibSp                                        0\n",
       "Parch                                        0\n",
       "Ticket                                  113051\n",
       "Fare                                     27.75\n",
       "Cabin                                     C111\n",
       "Embarked                                     C\n",
       "Name: 452, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "df.loc[452]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}