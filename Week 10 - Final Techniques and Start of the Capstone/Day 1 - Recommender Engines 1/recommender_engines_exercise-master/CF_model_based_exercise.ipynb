{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "#### Model Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting scikit-surprise==1.1.1\n  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\nRequirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-surprise==1.1.1) (1.0.1)\nRequirement already satisfied: numpy>=1.11.2 in c:\\users\\jesse\\appdata\\roaming\\python\\python38\\site-packages (from scikit-surprise==1.1.1) (1.19.5)\nRequirement already satisfied: scipy>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-surprise==1.1.1) (1.6.2)\nRequirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-surprise==1.1.1) (1.15.0)\nBuilding wheels for collected packages: scikit-surprise\n  Building wheel for scikit-surprise (setup.py): started\n  Building wheel for scikit-surprise (setup.py): finished with status 'done'\n  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp38-cp38-win_amd64.whl size=743350 sha256=02ce56ee7e2d49f8fea18b3a5c3fc7621024a865d53834c6d385f56ab55f383a\n  Stored in directory: c:\\users\\jesse\\appdata\\local\\pip\\cache\\wheels\\20\\91\\57\\2965d4cff1b8ac7ed1b6fa25741882af3974b54a31759e10b6\nSuccessfully built scikit-surprise\nInstalling collected packages: scikit-surprise\nSuccessfully installed scikit-surprise-1.1.1\nNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise==1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:57:37.226021Z",
     "start_time": "2020-04-30T11:57:36.904092Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import SVD from surprise\n",
    "from surprise import SVD\n",
    "\n",
    "# # import dataset from surprise\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "\n",
    "# import accuracy from surprise\n",
    "from surprise import accuracy\n",
    "\n",
    "# import train_test_split from surprise.model_selection\n",
    "from surprise.model_selection import train_test_split\n",
    "# import GridSearchCV from surprise.model_selection\n",
    "from surprise.model_selection import GridSearchCV\n",
    "# import cross_validate from surprise.model_selection\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with the [same data](https://drive.google.com/file/d/1WvTmAfO09TCX7xp7uu06__ziic7JnrL5/view?usp=sharing) we used in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratings = pd.read_csv('BX-Book-Ratings.csv',sep=\";\", encoding=\"latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create surprise dataset from book_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 10))\n",
    "\n",
    "# Loads Pandas dataframe\n",
    "data = Dataset.load_from_df(book_ratings, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* split data to train and test set, use test size 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use SVD (with default settings) to create recommendations for each user\n",
    "    - print default model's rmse that was computed on the test set (using object accuracy we imported in the beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 3.5095\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.509497978404905"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create parameters grid, use this params:\n",
    "* 'n_factors': [110, 120, 140, 160]\n",
    "* 'reg_all': [0.08, 0.1, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_factors': [110, 120, 140, 160],\n",
    "              'reg_all': [0.08, 0.1, 0.15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:58:23.235255Z",
     "start_time": "2020-04-30T11:58:23.230908Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate GridSearch with SVD as model, our pre-defined parameter grid and rmse and mae as evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:58:48.630386Z",
     "start_time": "2020-04-30T11:58:48.622574Z"
    }
   },
   "source": [
    "* fit GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print best RMSE score from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.4425916334620577\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* predict test set with optimal model based on `RMSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_factors': 160, 'reg_all': 0.15}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T12:02:09.347648Z",
     "start_time": "2020-04-30T12:02:09.203949Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print optimal model's RMSE that was computed on test set\n",
    "    - is it better than the default parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T12:02:09.507946Z",
     "start_time": "2020-04-30T12:02:09.485329Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}